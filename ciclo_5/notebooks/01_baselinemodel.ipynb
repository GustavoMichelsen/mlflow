{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f9421f-5d10-4c8b-8828-324f94ad964b",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3813710-7dd2-4c12-a5ba-45931be00e13",
   "metadata": {},
   "source": [
    "## 0.1 Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb869eb-0183-4621-89fa-d2f37d4b9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab697d9-61c5-4f11-953e-53e075e9e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import joblib\n",
    "from sklearn.pipeline              import Pipeline\n",
    "from sklearn.preprocessing         import StandardScaler\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "from feature_engine.imputation     import MeanMedianImputer\n",
    "from feature_engine.wrappers       import SklearnTransformerWrapper\n",
    "from sklearn.linear_model          import LogisticRegression\n",
    "\n",
    "from utils.utils               import load_config_file\n",
    "from data.dataload             import DataLoad\n",
    "from data.datavalidation       import DataValidation\n",
    "from data.datatranformation    import DataTransformation\n",
    "from data.datapreprocessing    import DataPreprocess\n",
    "from train.train               import TrainModel\n",
    "from evaluation.classfier_eval import ModelEvaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0039c-54c2-4717-9625-f85991fe3cfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.2 Funções de Ajuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ad8c8-af33-4c07-b9b8-513074d70491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a85c18d-1c7e-421d-bb0c-64a17fc4f7d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.3 Configurações do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada2c87a-909d-4d9f-b4b4-aa3d0e38dd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deixar o jupyper em widescreen\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# Seta o máximo de colunas e linhas que o pandas vai exibir\n",
    "# pd.set_option('display.max_columns', 20)\n",
    "# pd.set_option('display.max_rows', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76bfc1-a466-4beb-856d-98a3ce66ee89",
   "metadata": {},
   "source": [
    "# 1. DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c6b0b9-7fc0-4d1a-9955-5e05894c2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>TaxaDeUtilizacaoDeLinhasNaoGarantidas</th>\n",
       "      <th>Idade</th>\n",
       "      <th>NumeroDeVezes30-59DiasAtrasoNaoPior</th>\n",
       "      <th>TaxaDeEndividamento</th>\n",
       "      <th>RendaMensal</th>\n",
       "      <th>NumeroDeLinhasDeCreditoEEmprestimosAbertos</th>\n",
       "      <th>NumeroDeVezes90DiasAtraso</th>\n",
       "      <th>NumeroDeEmprestimosOuLinhasImobiliarias</th>\n",
       "      <th>NumeroDeVezes60-89DiasAtrasoNaoPior</th>\n",
       "      <th>NumeroDeDependentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  TaxaDeUtilizacaoDeLinhasNaoGarantidas  Idade  \\\n",
       "0       1                               0.766127     45   \n",
       "\n",
       "   NumeroDeVezes30-59DiasAtrasoNaoPior  TaxaDeEndividamento  RendaMensal  \\\n",
       "0                                    2             0.802982       9120.0   \n",
       "\n",
       "   NumeroDeLinhasDeCreditoEEmprestimosAbertos  NumeroDeVezes90DiasAtraso  \\\n",
       "0                                          13                          0   \n",
       "\n",
       "   NumeroDeEmprestimosOuLinhasImobiliarias  \\\n",
       "0                                        6   \n",
       "\n",
       "   NumeroDeVezes60-89DiasAtrasoNaoPior  NumeroDeDependentes  \n",
       "0                                    0                  2.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoad()\n",
    "df = dl.load_data('train_dataset_name')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b472c6a-a5ff-43da-a517-ce3eab8d16cc",
   "metadata": {},
   "source": [
    "# 2.Data Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3818fe91-fd66-42c9-9c13-6b11dbe24621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-05 14:54:28 [info     ] Validação Concluída           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DataValidation()\n",
    "dv.run(dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f93430-0b04-497e-9f8c-813617a2adab",
   "metadata": {},
   "source": [
    "# 3. DataTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc978699-e9b0-423a-a5e1-a5a608fe583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataTransformation(df)\n",
    "X_train, X_val, y_train, y_val = dt.train_test_spliting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc4781-4c29-49b9-90e8-bca4b450a204",
   "metadata": {},
   "source": [
    "# 4. Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf31039-cf37-4dad-aa31-39c1db91f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b384bf-de05-4ef9-9894-746f1eebde69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1704470502137, experiment_id='1', last_update_time=1704470502137, lifecycle_stage='active', name='prob_learng', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000/')\n",
    "mlflow.set_experiment('prob_learng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "503b4f9c-3ce8-4d7b-9a95-bab33f4cf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='baseline'):\n",
    "    mlflow.set_tag('model_name', 'lr_baseline')\n",
    "\n",
    "    # 1. Processar os dados\n",
    "    pipe = Pipeline([('imputer',  MeanMedianImputer(variables=load_config_file().get('vars_imputer'))),\n",
    "                     ('scaler', SklearnTransformerWrapper(StandardScaler())) ])\n",
    "    preprocessador = DataPreprocess(pipe=pipe)\n",
    "    preprocessador.train(X_train)\n",
    "\n",
    "    X_train = preprocessador.tranform(X_train)\n",
    "    X_val = preprocessador.tranform(X_val)\n",
    "    joblib.dump(preprocessador, '../models/preprocessador.joblib')\n",
    "\n",
    "    # 1.1 Logar um artefato\n",
    "\n",
    "    mlflow.log_artifacts('../models/preprocessador.joblib')\n",
    "\n",
    "    # 1.2 logar os parametros do processador\n",
    "\n",
    "    mlflow.log_params(params={'imputer': pipe['imputer'],\n",
    "                              'scaler' : pipe['scaler']})\n",
    "    \n",
    "    # 2.0 inicia o experimento com cross validation\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model_eval = ModelEvaluation(model, X_train, y_train)\n",
    "    roc_auc_curve = model_eval.cross_val_eval()\n",
    "\n",
    "    # 2.1 Logar o Resultado da Performance\n",
    "\n",
    "    mlflow.log_metric('train_roc_auc', roc_auc_curve.mean())\n",
    "    \n",
    "    # 3.0 Treinamento do Modelo\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 4.0 salvar as métricas de validação do modelo\n",
    "\n",
    "    y_pred = model_eval.model.predict_proba(X_val)[:, 1]\n",
    "    val_roc_curve = model_eval.evaluate_prediction(y_val, y_pred)\n",
    "    mlflow.log_metric('valid_roc_curve', val_roc_curve)\n",
    "\n",
    "     # 5.0 Logar o modelo criado\n",
    "    mlflow.sklearn.log_model(model,\n",
    "                             'lr_model',\n",
    "                             pyfunc_predict_fn='predict_proba')\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17448126-8a70-4d5b-b3d6-feed3407c23d",
   "metadata": {},
   "source": [
    "## 4.1 Experiment 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980c9869-36d8-43eb-937b-084722562cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import MetricThreshold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "645a740b-1ecb-4989-b06e-cc528603999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "Setuptools is replacing distutils.\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "Setuptools is replacing distutils.\n",
      "Downloading artifacts: 100%|█████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 41.58it/s]\n",
      "Downloading artifacts: 100%|█████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 41.87it/s]\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "2024/01/05 14:54:47 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2024/01/05 14:54:47 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "2024/01/05 14:54:47 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/01/05 14:54:47 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2024/01/05 14:54:47 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/01/05 14:54:49 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2024/01/05 14:54:49 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2024/01/05 14:54:52 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "2024/01/05 14:54:52 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/01/05 14:54:52 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2024/01/05 14:54:52 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/01/05 14:54:52 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "2024/01/05 14:54:52 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  File \"C:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
      "  0%|                                                                             | 46/30000 [00:26<4:45:16,  1.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 78\u001b[0m\n\u001b[0;32m     69\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mevaluate(candidate_model_uri, \n\u001b[0;32m     70\u001b[0m                 eval_data,\n\u001b[0;32m     71\u001b[0m                 targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     72\u001b[0m                 model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m                 validation_thresholds \u001b[38;5;241m=\u001b[39m thresholds,\n\u001b[0;32m     74\u001b[0m                 baseline_model \u001b[38;5;241m=\u001b[39m baseline_model_uri)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# explicabilidade do modelo com SHAP\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     81\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mend_run()\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\mlflow\\shap\\__init__.py:275\u001b[0m, in \u001b[0;36mlog_explanation\u001b[1;34m(predict_function, features, artifact_path)\u001b[0m\n\u001b[0;32m    273\u001b[0m background_data \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mkmeans(features, \u001b[38;5;28mmin\u001b[39m(_MAXIMUM_BACKGROUND_DATA_SIZE, \u001b[38;5;28mlen\u001b[39m(features)))\n\u001b[0;32m    274\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mKernelExplainer(predict_function, background_data)\n\u001b[1;32m--> 275\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m _log_numpy(explainer\u001b[38;5;241m.\u001b[39mexpected_value, _BASE_VALUES_FILE_NAME, artifact_path)\n\u001b[0;32m    278\u001b[0m _log_numpy(shap_values, _SHAP_VALUES_FILE_NAME, artifact_path)\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\shap\\explainers\\_kernel.py:244\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[0;32m    243\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[1;32m--> 244\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    246\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\shap\\explainers\\_kernel.py:448\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[1;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m phi_var \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgroups_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD))\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD):\n\u001b[1;32m--> 448\u001b[0m     vphi, vphi_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m     phi[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvaryingInds, d] \u001b[38;5;241m=\u001b[39m vphi\n\u001b[0;32m    450\u001b[0m     phi_var[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvaryingInds, d] \u001b[38;5;241m=\u001b[39m vphi_var\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\shap\\explainers\\_kernel.py:596\u001b[0m, in \u001b[0;36mKernelExplainer.solve\u001b[1;34m(self, fraction_evaluated, dim)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, fraction_evaluated, dim):\n\u001b[1;32m--> 596\u001b[0m     eyAdj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinkfv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mey\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfnull[dim])\n\u001b[0;32m    597\u001b[0m     s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaskMatrix, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;66;03m# do feature selection if we have not well enumerated the space\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\numpy\\lib\\function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_as_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\numpy\\lib\\function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[0;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vectorize_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\numpy\\lib\\function_base.py:2453\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2450\u001b[0m ufunc, otypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ufunc_and_otypes(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m   2452\u001b[0m \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m-> 2453\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ufunc(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mnout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\Servidor\\OneDrive - CALCADOS BEIRA RIO S A\\Documentos\\repos\\mlflow\\mlflow\\Lib\\site-packages\\numpy\\lib\\function_base.py:2453\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2450\u001b[0m ufunc, otypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ufunc_and_otypes(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m   2452\u001b[0m \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m-> 2453\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [asanyarray(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m   2455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ufunc(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mnout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='baseline'):\n",
    "    mlflow.set_tag('model_name', 'lr_baseline')\n",
    "\n",
    "    # 1. Processar os dados\n",
    "    pipe = Pipeline([('imputer',  MeanMedianImputer(variables=load_config_file().get('vars_imputer'))),\n",
    "                     ('discretizer', EqualFrequencyDiscretiser(variables=load_config_file().get('vars_discritiser'))),\n",
    "                     ('scaler', SklearnTransformerWrapper(StandardScaler())) ])\n",
    "    preprocessador = DataPreprocess(pipe=pipe)\n",
    "    preprocessador.train(X_train)\n",
    "\n",
    "    X_train = preprocessador.tranform(X_train)\n",
    "    X_val = preprocessador.tranform(X_val)\n",
    "    joblib.dump(preprocessador, '../models/preprocessador.joblib')\n",
    "\n",
    "    # 1.1 Logar um artefato\n",
    "\n",
    "    mlflow.log_artifacts('../models/preprocessador.joblib')\n",
    "\n",
    "    # 1.2 logar os parametros do processador\n",
    "\n",
    "    mlflow.log_params(params={'imputer': pipe['imputer'],\n",
    "                              'discretizer' : pipe['discretizer'],\n",
    "                              'scaler' : pipe['scaler']})\n",
    "    \n",
    "    # 2.0 inicia o experimento com cross validation\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model_eval = ModelEvaluation(model, X_train, y_train, n_splits=5)\n",
    "    roc_auc_curve = model_eval.cross_val_eval()\n",
    "\n",
    "    # 2.1 Logar o Resultado da Performance\n",
    "\n",
    "    mlflow.log_metric('train_roc_auc', roc_auc_curve.mean())\n",
    "    \n",
    "    # 3.0 Treinamento do Modelo\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 4.0 salvar as métricas de validação do modelo\n",
    "\n",
    "    y_pred = model_eval.model.predict_proba(X_val)[:, 1]\n",
    "    val_roc_curve = model_eval.evaluate_prediction(y_val, y_pred)\n",
    "    mlflow.log_metric('valid_roc_curve', val_roc_curve)\n",
    "\n",
    "     # 5.0 Logar o modelo criado\n",
    "    candidate_model_uri = mlflow.sklearn.log_model(model,\n",
    "                                                   'lr_model').model_uri\n",
    "\n",
    "    ######\n",
    "\n",
    "    signature = infer_signature(X_val, y_val)\n",
    "\n",
    "    eval_data = X_val\n",
    "    eval_data['label'] = y_val\n",
    "\n",
    "    thresholds = {\n",
    "                     'accuracy_score': MetricThreshold(threshold=0.7,\n",
    "                                                       min_absolute_change=0.05,\n",
    "                                                       min_relative_change=0.05,\n",
    "                                                       greater_is_better=True)\n",
    "                 }\n",
    "\n",
    "    baseline_model = DummyClassifier(strategy='uniform').fit(X_train, y_train)\n",
    "    baseline_model_uri = mlflow.sklearn.log_model(baseline_model,\n",
    "                                                  'baseline_model',\n",
    "                                                  signature=signature).model_uri\n",
    "\n",
    "    # processo responsável por avaliar o modelo do mlflow\n",
    "    mlflow.evaluate(candidate_model_uri, \n",
    "                    eval_data,\n",
    "                    targets = \"label\",\n",
    "                    model_type = \"classifier\",\n",
    "                    validation_thresholds = thresholds,\n",
    "                    baseline_model = baseline_model_uri)\n",
    "\n",
    "    # explicabilidade do modelo com SHAP\n",
    "\n",
    "    mlflow.shap.log_explanation(model.predict,\n",
    "                                X_val.drop('label', axis=1)) \n",
    "    \n",
    "    mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
